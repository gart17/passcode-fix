{
  "name": "PASSCoDe-fix",
  "tagline": "Fixing convergence problems in Parallel ASynchronous Stochastic dual Co-ordinate Descent (PASSCoDe) ",
  "body": "PASSCoDe-fix\r\n========================\r\nPASSCoDe-fix is based on the PASSCoDe (Parallel ASynchronous Stochastic dual Co-ordinate Descent)\r\nalgorithm, and aim to fix the divergence problem of PASSCoDe in highly parallel situations.\r\nPlease note that the current version only supports binary classification (with label +1 and -1),\r\nand only implemented limited dual solvers in the LIBLINEAR (see Usage below).\r\nFor more details about this algorithm please refer to the following papers:\r\n\r\n```\r\nFixing the Convergence Problems in Parallel Asynchronous Dual Coordinate Descent,\r\nHuan Zhang and Cho-Jui Hsieh\r\n\r\nPASSCoDe: Parallel ASynchronous Stochastic dual Co-ordinate Descent, \r\nC.-J. Hsieh, H.-F. Yu, and I. S. Dhillon\r\n```\r\n\r\nBuild\r\n---------------\r\n\r\nWe require the following environment to build PASSCoDe-fix:\r\n\r\n- GNU Compiler Collection (GCC) 4.7.1 or newer versions, with C++11 and OpenMP support\r\n- Unix Systems (If you are in Mac OS, please install GCC instead of the LLVM compiler shipped with the Xcode command line tools.\r\n\r\nTo build the program, simply run `make`. Two binaries, `train` (for training without shrinking)\r\nand `train-shrink` (for training with shrinking) will be built. In general training with shrinking is faster and preferred.\r\n\r\nData Preparation \r\n----------------\r\n\r\nPlease download the datasets from LIBSVM datasets\r\nhttp://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html\r\nand convert it to the binary format used for PASSCoDe-fix. \r\n\r\n```\r\n./convert2binary training_set_file [training_binary]\r\n```\r\n\r\n\r\nUsage\r\n----------------\r\n\r\nThe new solvers added in this version is PASSCoDe-Atomic-fix and PASSCoDe-Wild-fix for L1-loss\r\nand L2-loss support vector classifications.\r\nThey can be invoked by set the type of solver to 55, 57, 35 and 37, respectively.\r\nPlease note that in our paper only ATOMIC-fix based algorithms are analyzed,\r\nhowever Wild-fix might give you best performance for certain datasets.\r\n\r\n```\r\n./train[-shink] [options] training_set_file test_set_file\r\noptions:\r\n-s type : set type of solver (default 31)\r\n\t31 -- L2-regularized L2-loss support vector classification PASSCoDe-Wild (dual)\r\n\t33 -- L2-regularized L1-loss support vector classification PASSCoDe-Wild (dual)\r\n\t35 -- L2-regularized L2-loss support vector classification PASSCoDe-Wild-fix (dual)\r\n\t37 -- L2-regularized L1-loss support vector classification PASSCoDe-Wild-fix (dual)\r\n\t41 -- L2-regularized L2-loss support vector classification PASSCoDe-LOCK (dual)\r\n\t43 -- L2-regularized L1-loss support vector classification PASSCoDe-LOCK (dual)\r\n\t51 -- L2-regularized L2-loss support vector classification PASSCoDe-ATOMIC (dual)\r\n\t53 -- L2-regularized L1-loss support vector classification PASSCoDe-ATOMIC (dual)\r\n\t55 -- L2-regularized L2-loss support vector classification PASSCoDe-ATOMIC-fix (dual)\r\n\t57 -- L2-regularized L1-loss support vector classification PASSCoDe-ATOMIC-fix (dual)\r\n\t61 -- L2-regularized L2-loss support vector classification CoCoA (dual)\r\n\t63 -- L2-regularized L1-loss support vector classification CoCoA (dual)\r\n\t71 -- L2-regularized L2-loss support vector classification ASCD (dual)\r\n\t73 -- L2-regularized L1-loss support vector classification ASCD (dual)\r\n-c cost : set the parameter C (default 1)\r\n-n nr_threads : the number of threads\r\n-t max_iterations: the max number of iterations (default 100)\r\n-e epsilon : set tolerance of termination criterion\r\n-b binary_mode : if binary_mode = 1, read binary format (default 1)\r\n```\r\n\r\n\r\nAdditional Information\r\n----------------------\r\n\r\nIf your have any questions or comments, please open an issue on Github,\r\nor send an email to ecezhang@ucdavis.edu. We appreciate your feedback.\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}